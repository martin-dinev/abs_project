{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": ""
    },
    "ExecuteTime": {
     "end_time": "2023-06-14T11:06:20.431885200Z",
     "start_time": "2023-06-14T11:06:20.421885500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)  # this goes *before* tf import\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError, MSE\n",
    "from tensorflow import reduce_mean, convert_to_tensor, squeeze, float32, GradientTape\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['AUTOGRAPH_VERBOSITY'] = '1'\n",
    "tf.autograph.set_verbosity(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment lux_ai_s2 failed: No module named 'pettingzoo'\n"
     ]
    }
   ],
   "source": [
    "from kaggle_environments import make"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T11:06:21.022000600Z",
     "start_time": "2023-06-14T11:06:20.826000700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-14T11:06:21.309269400Z",
     "start_time": "2023-06-14T11:06:21.295271100Z"
    }
   },
   "outputs": [],
   "source": [
    "from deep_q_learning import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "env = make(\"connectx\", debug=False)\n",
    "\n",
    "state_space_shape = tuple([len(env.state[0].observation.board)])\n",
    "num_actions = env.configuration.columns\n",
    "num_episodes = 1000\n",
    "learning_rate = 0.01\n",
    "discount_factor = 0.99\n",
    "batch_size = 256\n",
    "memory_size = 1024\n",
    "\n",
    "epsilon = 1\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 1.3 * (epsilon - epsilon_min) / num_episodes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T11:06:21.855476700Z",
     "start_time": "2023-06-14T11:06:21.815477700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def build_model(state_space_shape, num_actions, learning_rate):\n",
    "    input_layer = Input(shape=state_space_shape)\n",
    "    x = Dense(42)(input_layer)\n",
    "    x = Dense(42)(x)\n",
    "    x = Dense(num_actions)(x)\n",
    "\n",
    "    m = Model(inputs=input_layer, outputs=x)\n",
    "    m.compile(Adam(learning_rate=learning_rate), loss=MeanSquaredError())\n",
    "\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T11:06:23.653307800Z",
     "start_time": "2023-06-14T11:06:23.642304800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = build_model(state_space_shape, num_actions, learning_rate)\n",
    "target_model = build_model(state_space_shape, num_actions, learning_rate)\n",
    "agent = DQN(state_space_shape, num_actions, model, target_model,\n",
    "            learning_rate, discount_factor, batch_size, memory_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T11:06:24.983946400Z",
     "start_time": "2023-06-14T11:06:24.797177100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def process_state(_state):\n",
    "    return np.asarray(_state.board)\n",
    "\n",
    "\n",
    "def preprocess_reward(_reward):\n",
    "    return (20 if _reward == 1 else 5 if _reward == 0 else -1) if _reward is not None else -20\n",
    "\n",
    "\n",
    "def postprocess_action(_action):\n",
    "    return round(_action)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T11:06:25.512820Z",
     "start_time": "2023-06-14T11:06:25.497822700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from my_utils import my_train, my_evaluate, mean_reward"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T11:06:26.323648500Z",
     "start_time": "2023-06-14T11:06:26.304270300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [20:56<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "configuration = {\n",
    "    \"num_episodes\": num_episodes,\n",
    "    \"process_state\": process_state, \"process_reward\": preprocess_reward, \"process_action\": postprocess_action,\n",
    "    \"epsilon\": epsilon, \"epsilon_decay\": epsilon_decay, \"epsilon_min\": epsilon_min\n",
    "}\n",
    "\n",
    "my_train(agent, opponent=\"negamax\", **configuration)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T11:27:23.849690400Z",
     "start_time": "2023-06-14T11:06:27.524655600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "agent.save('connectx-flat', 1000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "agent.load('connectx-flat', 1000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def my_agent(observation, configuration):\n",
    "    _state = process_state(observation)\n",
    "    _action = agent.get_action(_state, 0)\n",
    "    _action = postprocess_action(_action)\n",
    "    return _action\n",
    "\n",
    "\n",
    "def fixed_agent(observation, configuration):\n",
    "    return 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:42<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Random Agent: W: 72; L: 23; M: 5; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:22<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Negamax Agent: W: 4; L: 83; M: 13; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:22<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Agent vs Negamax Agent: W: 6; L: 92; M: 0; O: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 22.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Agent vs Random Agent: W: 61; L: 0; M: 39; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:55<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Agent vs Negamax Agent: W: 0; L: 18; M: 82; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:20<00:00,  4.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Fixed Agent W: 100; L: 0; M: 0; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"My Agent vs Random Agent:\", mean_reward(my_evaluate(\"connectx\", [my_agent, \"random\"])))\n",
    "print(\"My Agent vs Negamax Agent:\", mean_reward(my_evaluate(\"connectx\", [my_agent, \"negamax\"])))\n",
    "print(\"Random Agent vs Negamax Agent:\", mean_reward(my_evaluate(\"connectx\", [\"random\", \"negamax\"])))\n",
    "print(\"Fixed Agent vs Random Agent:\", mean_reward(my_evaluate(\"connectx\", [fixed_agent, \"random\"])))\n",
    "print(\"Fixed Agent vs Negamax Agent:\", mean_reward(my_evaluate(\"connectx\", [fixed_agent, \"negamax\"])))\n",
    "print(\"My Agent vs Fixed Agent\", mean_reward(my_evaluate(\"connectx\", [my_agent, fixed_agent])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [23:30<00:00,  1.41s/it]\n",
      "100%|██████████| 100/100 [00:46<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Random Agent: W: 79; L: 9; M: 12; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:41<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Negamax Agent: W: 5; L: 67; M: 28; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:37<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Agent vs Negamax Agent: W: 1; L: 97; M: 0; O: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 22.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Agent vs Random Agent: W: 72; L: 0; M: 28; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:00<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed Agent vs Negamax Agent: W: 0; L: 22; M: 78; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:25<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Fixed Agent W: 0; L: 100; M: 0; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "configuration = {\n",
    "    \"num_episodes\": 1000,\n",
    "    \"process_state\": process_state, \"process_reward\": preprocess_reward, \"process_action\": postprocess_action,\n",
    "    \"epsilon\": epsilon, \"epsilon_decay\": epsilon_decay, \"epsilon_min\": epsilon_min\n",
    "}\n",
    "\n",
    "my_train(agent, opponent=\"negamax\", **configuration)\n",
    "agent.save('connectx-flat', 2000)\n",
    "agent.load('connectx-flat', 2000)\n",
    "\n",
    "print(\"My Agent vs Random Agent:\", mean_reward(my_evaluate(\"connectx\", [my_agent, \"random\"])))\n",
    "print(\"My Agent vs Negamax Agent:\", mean_reward(my_evaluate(\"connectx\", [my_agent, \"negamax\"])))\n",
    "print(\"Random Agent vs Negamax Agent:\", mean_reward(my_evaluate(\"connectx\", [\"random\", \"negamax\"])))\n",
    "print(\"Fixed Agent vs Random Agent:\", mean_reward(my_evaluate(\"connectx\", [fixed_agent, \"random\"])))\n",
    "print(\"Fixed Agent vs Negamax Agent:\", mean_reward(my_evaluate(\"connectx\", [fixed_agent, \"negamax\"])))\n",
    "print(\"My Agent vs Fixed Agent\", mean_reward(my_evaluate(\"connectx\", [my_agent, fixed_agent])))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T12:35:21.717296700Z",
     "start_time": "2023-06-14T12:05:14.624581900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [23:13<00:00,  1.39s/it]\n",
      "100%|██████████| 100/100 [00:42<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Random Agent: W: 76; L: 23; M: 1; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:26<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Negamax Agent: W: 6; L: 83; M: 11; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:24<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Fixed Agent W: 100; L: 0; M: 0; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "configuration = {\n",
    "    \"num_episodes\": 1000,\n",
    "    \"process_state\": process_state, \"process_reward\": preprocess_reward, \"process_action\": postprocess_action,\n",
    "    \"epsilon\": epsilon, \"epsilon_decay\": epsilon_decay, \"epsilon_min\": epsilon_min\n",
    "}\n",
    "\n",
    "my_train(agent, opponent=\"negamax\", **configuration)\n",
    "agent.save('connectx-flat', 3000)\n",
    "agent.load('connectx-flat', 3000)\n",
    "\n",
    "print(\"My Agent vs Random Agent:\", mean_reward(my_evaluate(\"connectx\", [my_agent, \"random\"])))\n",
    "print(\"My Agent vs Negamax Agent:\", mean_reward(my_evaluate(\"connectx\", [my_agent, \"negamax\"])))\n",
    "print(\"My Agent vs Fixed Agent\", mean_reward(my_evaluate(\"connectx\", [my_agent, fixed_agent])))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T14:26:50.599980Z",
     "start_time": "2023-06-14T14:00:02.413837600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [27:30<00:00,  1.65s/it]\n",
      "100%|██████████| 100/100 [00:56<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Random Agent: W: 80; L: 20; M: 0; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:41<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Negamax Agent: W: 9; L: 88; M: 3; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:29<00:00,  3.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Fixed Agent W: 0; L: 100; M: 0; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "configuration = {\n",
    "    \"num_episodes\": 1000,\n",
    "    \"process_state\": process_state, \"process_reward\": preprocess_reward, \"process_action\": postprocess_action,\n",
    "    \"epsilon\": epsilon, \"epsilon_decay\": epsilon_decay, \"epsilon_min\": epsilon_min\n",
    "}\n",
    "\n",
    "my_train(agent, opponent=\"negamax\", **configuration)\n",
    "agent.save('connectx-flat', 4000)\n",
    "agent.load('connectx-flat', 4000)\n",
    "\n",
    "print(\"My Agent vs Random Agent:\", mean_reward(my_evaluate(\"connectx\", [my_agent, \"random\"])))\n",
    "print(\"My Agent vs Negamax Agent:\", mean_reward(my_evaluate(\"connectx\", [my_agent, \"negamax\"])))\n",
    "print(\"My Agent vs Fixed Agent\", mean_reward(my_evaluate(\"connectx\", [my_agent, fixed_agent])))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T15:20:45.923331500Z",
     "start_time": "2023-06-14T14:49:07.876876400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [26:07<00:00,  1.57s/it]\n",
      "100%|██████████| 100/100 [00:52<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Random Agent: W: 82; L: 18; M: 0; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:35<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Negamax Agent: W: 5; L: 91; M: 4; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:28<00:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Agent vs Fixed Agent W: 0; L: 100; M: 0; O: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "configuration = {\n",
    "    \"num_episodes\": 1000,\n",
    "    \"process_state\": process_state, \"process_reward\": preprocess_reward, \"process_action\": postprocess_action,\n",
    "    \"epsilon\": epsilon, \"epsilon_decay\": epsilon_decay, \"epsilon_min\": epsilon_min\n",
    "}\n",
    "\n",
    "my_train(agent, opponent=\"negamax\", **configuration)\n",
    "agent.save('connectx-flat', 5000)\n",
    "agent.load('connectx-flat', 5000)\n",
    "\n",
    "print(\"My Agent vs Random Agent:\", mean_reward(my_evaluate(\"connectx\", [my_agent, \"random\"])))\n",
    "print(\"My Agent vs Negamax Agent:\", mean_reward(my_evaluate(\"connectx\", [my_agent, \"negamax\"])))\n",
    "print(\"My Agent vs Fixed Agent\", mean_reward(my_evaluate(\"connectx\", [my_agent, fixed_agent])))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-14T15:50:50.137833100Z",
     "start_time": "2023-06-14T15:20:45.959630500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
